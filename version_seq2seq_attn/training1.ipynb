{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "UNK, PAD, BOS, EOS = '<unk>', '<pad>', '<bos>', '<eos>'\n",
    "def build_vocab(processed_text,processed_news,min_freq=3):\n",
    "    \"\"\"构建词典\"\"\"\n",
    "    all_content = []\n",
    "    all_content.extend(processed_text)\n",
    "    all_content.extend(processed_news)\n",
    "    \n",
    "    # 统计词频\n",
    "    tokens_dict = {}\n",
    "    for content in all_content:\n",
    "        for token in content:\n",
    "            tokens_dict[token] = tokens_dict.get(token,0)+1\n",
    "\n",
    "    vocab = {}\n",
    "    extend_vocab = {}\n",
    "    idx = 4\n",
    "    # 映射 token and id\n",
    "    for k,v in tokens_dict.items():\n",
    "        if v>=min_freq:\n",
    "            vocab[k] = idx\n",
    "            idx+=1\n",
    "        elif v>1:\n",
    "            extend_vocab[k] = -1\n",
    "    for k in extend_vocab.keys():\n",
    "        extend_vocab[k] = idx\n",
    "        idx+=1\n",
    "    vocab.update({PAD:0, UNK:1, BOS:2, EOS:3})\n",
    "    return vocab, extend_vocab\n",
    "\n",
    "def build_dataset(vocab, extend_vocab, processed_content, max_len, is_extend_vocab=False, sentence_type=None):\n",
    "    \"\"\"pad token and to id\"\"\"\n",
    "    content = []\n",
    "    extend_content = []\n",
    "    \n",
    "    for sent in processed_content:\n",
    "        if sentence_type == \"summary\":\n",
    "            # 为摘要加上结尾符\n",
    "            if len(sent)<max_len:\n",
    "                sent.extend([EOS]+[PAD]*(max_len-len(sent)))\n",
    "            else:\n",
    "                sent[:] = sent[:max_len] + [EOS]\n",
    "        else:\n",
    "            sent[:] = sent[:max_len] + [PAD]*np.maximum(max_len-len(sent),0)\n",
    "        \n",
    "        if sentence_type == \"summary\":\n",
    "            sent_id = [extend_vocab[token] if token in extend_vocab else vocab.get(token,vocab[UNK]) for token in sent]\n",
    "        else:\n",
    "            sent_id = [vocab.get(token,vocab[UNK]) for token in sent]\n",
    "        if is_extend_vocab:\n",
    "            extend_id = [extend_vocab[token] if token in extend_vocab else vocab.get(token,vocab[UNK]) for token in sent]\n",
    "                \n",
    "        content.append(sent_id)\n",
    "        if is_extend_vocab: extend_content.append(extend_id)\n",
    "    return torch.tensor(content), torch.tensor(extend_content)\n",
    "\n",
    "def get_pretrained_embedding(vocab,pretrain_embedding_path,vector_dim=300):\n",
    "    \"\"\"加载词向量，vocab的token_id与embedding的index对齐，用作torch.nn.Embedding.from_pretrained(Embedding)\"\"\"\n",
    "    with open(pretrain_embedding_path, 'r+', encoding='utf-8') as f:\n",
    "        embeddings = torch.rand(len(vocab),vector_dim)\n",
    "        for _,line in enumerate(f.readlines()):\n",
    "            if _==0: continue\n",
    "            line = line.strip().split(' ')\n",
    "            if line[0] in vocab:\n",
    "                idx = vocab[line[0]]\n",
    "                embeddings[idx] = torch.tensor([float(i) for i in line[1:]], dtype=torch.float32)\n",
    "        for i in range(4):\n",
    "            embeddings[idx] = torch.ones(vector_dim, dtype=torch.float32)*float(i/100)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"单层双向GRU\n",
    "    ！！优化：n_layers增加\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, n_layers=1,\n",
    "                 dropout=0.0, use_pretrained_embeddings=True, pre_embeddings=None):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        if use_pretrained_embeddings:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pre_embeddings)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        self.gru = nn.GRU(self.embed_size, self.hidden_size, self.n_layers, bidirectional=True)\n",
    "        \n",
    "        self.ln = nn.LayerNorm((self.hidden_size,), eps=1e-5, elementwise_affine=True)\n",
    "    \n",
    "    def forward(self, inputs, init_hidden):\n",
    "        \"\"\"\n",
    "        :parma inputs: [batch, seq_len]\n",
    "        :parma init_hidden: None\n",
    "        \"\"\"\n",
    "        # [batch, seq_len, embed_size] -> [seq_len, batch, embed_size], 适应GRU的输入\n",
    "        inputs = self.ln(self.embedding(inputs).permute(1,0,2))\n",
    "        # outputs: [seq_len, batch, hidden_size*num_direction], hidden_states: [n_layers*num_direction, batch, hidden_size]\n",
    "        outputs,hidden_states = self.gru(inputs,init_hidden)\n",
    "        outputs = outputs[:,:,:self.hidden_size]+outputs[:,:,self.hidden_size:]\n",
    "        outputs = outputs.permute(1,0,2) # [batch, seq_len, embed_size]\n",
    "        hidden_states = hidden_states[:1,:,:] + hidden_states[1:,:,:]\n",
    "        return outputs, hidden_states\n",
    "    \n",
    "    def get_init_hidden(self):\n",
    "        return None\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"双层单项GRU\n",
    "    !!优化：双线性层输出；copy机制；目标函数优化\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, n_layers=1, dropout=0.1,\n",
    "                 use_pretrained_embeddings=True, pre_embeddings=None, use_pointer_gen=True, is_coverage=True):\n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.use_pointer_gen = use_pointer_gen\n",
    "        \n",
    "        self.attention = Attention(config.max_len_text, self.hidden_size, is_coverage=is_coverage)\n",
    "        \n",
    "        if use_pretrained_embeddings:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pre_embeddings)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        # 衡量一个词是生成的还是复制的\n",
    "        if self.use_pointer_gen:\n",
    "            self.p_gen_sig = nn.Sequential(\n",
    "                nn.Linear(self.hidden_size*2+self.embed_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "            \n",
    "        # 解码器的输入时间步拼接上下文向量，过一个线性映射\n",
    "        self.x_context = nn.Linear(self.hidden_size+self.embed_size, self.embed_size)\n",
    "        # 对输入向量进行解码\n",
    "        self.gru = nn.GRU(self.embed_size, self.hidden_size, self.n_layers)\n",
    "        # 将解码状态St和上下文向量ht*拼接后经过两层线性层得到单词表分布P_vocab\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size*2, self.hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        )\n",
    "        \n",
    "        self.input_ln = nn.LayerNorm((hidden_size,), eps=1e-5, elementwise_affine=True)\n",
    "        self.hidden_ln = nn.LayerNorm((hidden_size,), eps=1e-5, elementwise_affine=True)\n",
    "        \n",
    "    def forward(self, inputs, dec_hidden, enc_outputs, enc_padding_mask, context_vector_t1,\n",
    "                enc_batch_extend_vocab, extra_zeros, coverage):\n",
    "        \"\"\"\n",
    "        :parma inputs: 时间步t的输入（训练时是y_true的输入，预测时是上一时间步的输出） [batch, 1]\n",
    "        :parma dec_hidden: 当前时间步的隐藏状态 [n_layers, batch, hidden_size]\n",
    "        :parma enc_outputs: encoder的所有时间步的隐藏状态 [batch, seq_len, hidden_size]\n",
    "        :parma enc_padding_mask: 对应pad的位置为-inf，其余为0 [batch, seq_len]\n",
    "        :parma context_vector_t1: 时间步t-1的上下文向量 [batch, hidden_size]\n",
    "        :parma enc_batch_extend_vocab: 原文章的编码，oov词汇用超过词汇表的编码 [batch, seq_len]\n",
    "        :parma extra_zeros: 文章oov词汇数量 [batch, extend_vocab_size]\n",
    "        :parma coverage: 用先前的注意力权重影响当前注意力权重的决策 [batch, seq_len]\n",
    "        \"\"\"\n",
    "        x = self.input_ln(self.embedding(inputs).squeeze(1)) # batch * embed_size\n",
    "        x = self.x_context(torch.cat((x,context_vector_t1),dim=1)) # batch * embed_size\n",
    "        dec_hidden = self.hidden_ln(dec_hidden)\n",
    "        # dec_output: [1, batch, hidden_size], s_t: [n_layers, batch, hidden_size]\n",
    "        dec_output,s_t = self.gru(x.unsqueeze(0), dec_hidden)\n",
    "        dec_output, s_t = dec_output[0], s_t[-1]\n",
    "        \n",
    "        # h_t: batch * hidden_size, atten_dist: batch * vocab_size, coverage_next: batch * vocab_size\n",
    "        h_t,atten_dist,coverage_next = self.attention(enc_outputs, s_t, enc_padding_mask, coverage)\n",
    "        \n",
    "        if self.training and config.is_coverage:\n",
    "            coverage = coverage_next\n",
    "        \n",
    "        p_gen = None\n",
    "        if self.use_pointer_gen:\n",
    "            p_gen_input = torch.cat((h_t, s_t, x),dim=1) # batch * hidden_size*3\n",
    "            p_gen = self.p_gen_sig(p_gen_input).clamp(min=1e-8)\n",
    "        \n",
    "        s_t_h_t = torch.cat((dec_output,h_t), dim=1) # batch * hidden_size*2\n",
    "        vocab_dist = F.softmax(self.out(s_t_h_t), dim=1)\n",
    "        \n",
    "        if self.use_pointer_gen:\n",
    "            vocab_dist_ = p_gen * vocab_dist # batch * vocab_size\n",
    "            atten_dist_ = (1-p_gen) * atten_dist # batch * seq_len\n",
    "\n",
    "            if extra_zeros is not None:\n",
    "                vocab_dist_ = torch.cat((vocab_dist_,extra_zeros), dim=1) # batch * vocab_size+seq_len\n",
    "                \n",
    "            final_dist = vocab_dist_.scatter_add(1, enc_batch_extend_vocab, atten_dist_).clamp(min=1e-8)\n",
    "        else:\n",
    "            final_dist = vocab_dist\n",
    "        \n",
    "        if config.is_coverage:\n",
    "            coverage_loss = torch.sum(torch.min(atten_dist, coverage), 1)\n",
    "        else:\n",
    "            coverage_loss=None\n",
    "        return torch.log(final_dist), s_t.unsqueeze(0), h_t, coverage, coverage_loss\n",
    "    \n",
    "    def get_init_hidden(self, enc_hidden):\n",
    "        # 直接使用encoder端输出的隐含向量作为decoder端的初始化\n",
    "        # enc_hidden: [n_layers*num_direction, batch, hidden_size]\n",
    "        return enc_hidden\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_seq_len, hidden_size, is_coverage=True):\n",
    "        super(Attention,self).__init__()\n",
    "        \n",
    "        self.enc_seq_len = enc_seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.is_coverage = is_coverage\n",
    "        \n",
    "        if is_coverage:\n",
    "            self.W_c = nn.Linear(1, self.hidden_size, bias=False)\n",
    "        self.W_h = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.W_s = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.V = nn.Linear(self.hidden_size, 1, bias=False)\n",
    "        \n",
    "        self.ln = nn.LayerNorm((hidden_size,), eps=1e-5, elementwise_affine=True)\n",
    "        \n",
    "    def forward(self, enc_output, dec_hidden, enc_padding_mask, coverage):\n",
    "        \"\"\"\n",
    "        :parma enc_outputs: [batch, seq_len, hidden_size]\n",
    "        :parma dec_hidden: [batch, hidden_size]\n",
    "        :parma enc_padding_mask: [batch, seq_len]\n",
    "        :parma coverage: [batch, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size,seq_len,enc_hidden_size = enc_output.size()\n",
    "        \n",
    "        # [batch*seq_len, hidden_size]\n",
    "        enc_outputs = enc_output.contiguous().view(-1,enc_hidden_size)\n",
    "        enc_feature = self.W_h(enc_outputs)\n",
    "        dec_feature = self.W_s(dec_hidden) # [batch, hidden_size]\n",
    "         # [batch*seq_len, hidden_size]\n",
    "        dec_feature = dec_feature.unsqueeze(1).expand(batch_size, seq_len, enc_hidden_size).contiguous()\n",
    "        dec_feature = dec_feature.view(-1,enc_hidden_size)\n",
    "        \n",
    "        atten_feature = enc_feature + dec_feature\n",
    "        if self.is_coverage:\n",
    "            coverage_input = coverage.view(-1, 1) # [batch*seq_len, 1]\n",
    "            coverage_feature = self.W_c(coverage_input)\n",
    "            atten_feature = atten_feature + coverage_feature\n",
    "        \n",
    "        # 注意力分数计算\n",
    "        e_t = self.V(torch.tanh(atten_feature)).view(batch_size,-1) # [batch, seq_len]\n",
    "        atten_dist = F.softmax(e_t + enc_padding_mask, dim=1)\n",
    "\n",
    "        # 时间步的atten分数乘以其隐向量，相加得到上下文向量\n",
    "        context_vector = self.ln(torch.bmm(atten_dist.unsqueeze(1),enc_output).squeeze(1)) # batch * hidden_size\n",
    "        atten_dist = atten_dist.squeeze(1)\n",
    "        \n",
    "        if self.is_coverage:\n",
    "            coverage = coverage + atten_dist\n",
    "\n",
    "        return context_vector, atten_dist, coverage\n",
    "    \n",
    "class PointerGenerator(nn.Module):\n",
    "    def __init__(self, encoder, decoder, extend_vocab_size, hidden_size):\n",
    "        super(PointerGenerator, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.extend_vocab_size = extend_vocab_size\n",
    "        \n",
    "    def forward(self, inputs, target, text_extend):\n",
    "        \"\"\"\n",
    "        :parma inputs: [batch, seq_len]\n",
    "        :parma target: [batch, target_seq_len]\n",
    "        :parma extend_token_id: [batch, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size,seq_len = inputs.size()\n",
    "        null_enc_state = self.encoder.get_init_hidden()\n",
    "        enc_output,enc_hidden  = self.encoder(inputs, null_enc_state)\n",
    "        \n",
    "        dec_hidden = self.decoder.get_init_hidden(enc_hidden)\n",
    "        dec_input = torch.tensor([config.spc_token[BOS]]*batch_size, dtype=torch.long, device=device)\n",
    "        \n",
    "        enc_padding_mask = []\n",
    "        for item in inputs:\n",
    "            enc_padding_mask.append([float('-inf') if i==0 else 0 for i in item]) # 0为pad id\n",
    "        enc_padding_mask = torch.tensor(enc_padding_mask, dtype=torch.float32, device=device)\n",
    "        \n",
    "        context_vector_t1, enc_batch_extend_vocab, extra_zeros, coverage = self.get_init_input_batch(text_extend, batch_size, enc_hidden.size(-1), seq_len)\n",
    "        \n",
    "        batch_output = torch.Tensor().to(device) # [batch, target_seq_len, vocab_size]\n",
    "        for y in target.permute(1,0): # y: seq_len * batch\n",
    "            dec_output, dec_hidden, context_vector_t1, coverage, coverage_loss = self.decoder(\n",
    "                dec_input, dec_hidden, enc_output, enc_padding_mask,\n",
    "                context_vector_t1, enc_batch_extend_vocab, extra_zeros, coverage\n",
    "            )\n",
    "            batch_output = torch.cat((batch_output,dec_output.unsqueeze(1)), dim=1)\n",
    "            \n",
    "            if random.uniform(0, 1) > 0.5 and self.training:\n",
    "                dec_input = y\n",
    "            else:\n",
    "                dec_input = dec_output.argmax(dim=1)\n",
    "        return batch_output, coverage_loss\n",
    "    \n",
    "    def get_init_input_batch(self, text_extend, batch_size, hidden_size, seq_len):\n",
    "        coverage = None\n",
    "        extra_zeros = None\n",
    "        enc_batch_extend_vocab = None\n",
    "        \n",
    "        context_vector_t1 = torch.zeros(batch_size, hidden_size, device=device)\n",
    "        \n",
    "        if config.is_coverage:\n",
    "            coverage = torch.zeros(batch_size, seq_len, device=device)\n",
    "        \n",
    "        if config.use_pointer_gen:\n",
    "            enc_batch_extend_vocab = text_extend\n",
    "            extra_zeros = torch.zeros(batch_size, self.extend_vocab_size, device=device)\n",
    "        return context_vector_t1, enc_batch_extend_vocab, extra_zeros, coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "# from transformers import (\n",
    "#     AdamW,\n",
    "#     get_cosine_schedule_with_warmup,\n",
    "#     get_linear_schedule_with_warmup\n",
    "# )\n",
    "from accelerate import Accelerator\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "PAD, BOS, EOS = \"<pad>\", \"<bos>\", \"<eos>\"\n",
    "accelerator = Accelerator(fp16=True, cpu=False)\n",
    "device = accelerator.device\n",
    "print('device:', device)\n",
    "\n",
    "def get_optim_shedu(named_parameters, total_steps, Hyparameters_config, use_scheduler=True):\n",
    "    ignored_params = [\"bias\", \"ln.weight\", \"embedding.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n,p in named_parameters if not any(i in n for i in ignored_params)],\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n,p in named_parameters if any(i in n for i in ignored_params[:-1])],\n",
    "            \"weight_decay\": 0.0\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n,p in named_parameters if ignored_params[-1] in n],\n",
    "            \"lr\": Hyparameters_config['lr']*0.1,\n",
    "            \"weight_decay\": 0.0\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    #optimizer = AdamW(model_parameters, lr=Hyparameters_config['lr'], weight_decay=Hyparameters_config['weight_decay'])\n",
    "    optimizer = optim.Adam(optimizer_parameters, lr=Hyparameters_config['lr'], weight_decay=Hyparameters_config['weight_decay'])\n",
    "    if use_scheduler:\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer = optimizer,\n",
    "            num_warmup_steps=0.1*total_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "    #     scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='max',\n",
    "    #         factor=Hyparameters_config['lr_gamma'],\n",
    "    #         patience=Hyparameters_config['patience']\n",
    "    #     )\n",
    "        return optimizer,scheduler\n",
    "    else:\n",
    "        return optimizer\n",
    "    \n",
    "def trainer(model, train_dataset, valid_dataset, num_epochs, Hyparameters_config, cov_loss_wt=1):\n",
    "    train_iter = DataLoader(train_dataset, Hyparameters_config['batch_size'], shuffle=True)\n",
    "    valid_iter = DataLoader(valid_dataset, Hyparameters_config['batch_size'], shuffle=True)\n",
    "    total_steps = len(train_iter)*num_epochs\n",
    "    \n",
    "    optimizer = get_optim_shedu(model.named_parameters(), total_steps, Hyparameters_config, use_scheduler=False)\n",
    "    \n",
    "    criterion = nn.NLLLoss(reduction='none')\n",
    "    model,optimizer = accelerator.prepare(model, optimizer)\n",
    "    \n",
    "    model.train()\n",
    "    accumulation_steps = 4 # 梯度累积\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_train, epoch_loss_eval, epoch_acc_train, epoch_acc_eval = 0, 0, 0, 0\n",
    "        start_time = time.time()\n",
    "        # count = 0\n",
    "        for text,news,text_extend in tqdm(train_iter, desc=\"training for epoch {}: \".format(epoch)):\n",
    "            text = text.long().to(device)\n",
    "            news = news.long().to(device)\n",
    "            text_extend = text_extend.long().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output,batch_coverage_loss = model(text, news, text_extend) # [batch, seq_len, vocab_size + extend_vocab_size]\n",
    "            \n",
    "            batch_loss_train,batch_acc_train = torch.tensor([0.0], device=device),torch.tensor([0.0])\n",
    "            # [batch, seq_len, vocab_size + extend_vocab_size]\n",
    "            for predicted, target in zip(output, news):\n",
    "                dec_mask_padding = (target!=0).to(dtype=torch.float32)\n",
    "                target_len = int(sum(dec_mask_padding).item()-1)\n",
    "                \n",
    "                batch_loss_train = batch_loss_train + torch.sum(dec_mask_padding * criterion(predicted, target)) / target_len\n",
    "                batch_acc_train += (target == predicted.argmax(dim=1)).sum().item() / target.size(0)\n",
    "            if config.is_coverage:\n",
    "                print(batch_loss_train, cov_loss_wt * torch.sum(batch_coverage_loss))\n",
    "                batch_loss_train = batch_loss_train/Hyparameters_config['batch_size'] + cov_loss_wt*torch.sum(batch_coverage_loss)\n",
    "                \n",
    "            Before = list(model.parameters())[1].clone() # 获取更新前模型的第0层权重\n",
    "            batch_loss_train = batch_loss_train #/ accumulation_steps\n",
    "            accelerator.backward(batch_loss_train)\n",
    "            \n",
    "            # 梯度截断\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "\n",
    "            # 参数更新\n",
    "            optimizer.step()\n",
    "            # if((count+1)%accumulation_steps)==0:\n",
    "            #     optimizer.step()\n",
    "            #     optimizer.zero_grad()\n",
    "            # count+=1\n",
    "            After = list(model.parameters())[1].clone()\n",
    "            print('encoder的第0层更新幅度：',torch.sum(After-Before))\n",
    "            epoch_loss_train += batch_loss_train.item()\n",
    "            epoch_acc_train += batch_acc_train.item() / Hyparameters_config['batch_size']\n",
    "            print(epoch_loss_train,epoch_acc_train)\n",
    "        \n",
    "            del text, news, text_extend, output, batch_coverage_loss, batch_loss_train, batch_acc_train\n",
    "        \n",
    "        # 参数保存\n",
    "        if epoch >= Hyparameters_config['save_state_epoch']:\n",
    "            path = './save_models/'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            accelerator.save(\n",
    "                {\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                },\n",
    "                path + f'epoch_{epoch+1}.pkl'\n",
    "            )\n",
    "        \n",
    "        # eval\n",
    "        with torch.no_grad():\n",
    "            for text,news,extend_token_id in tqdm(valid_iter, desc=\"evaluating for epoch {}: \".format(epoch)):\n",
    "                text = text.long()\n",
    "                news = news.long()\n",
    "                extend_token_id = extend_token_id.long()\n",
    "                \n",
    "                output,batch_coverage_loss = model(text.to(device), news.to(device), extend_token_id.to(device))\n",
    "                output,batch_coverage_loss = output.cpu(),batch_coverage_loss.cpu()\n",
    "                \n",
    "                batch_loss_eval,batch_acc_eval = torch.tensor([0.0]),torch.tensor([0.0])\n",
    "                for predicted,target in zip(output,news):\n",
    "                    dec_mask_padding = (target!=0).to(dtype=torch.float32)\n",
    "                    target_len = int(sum(dec_mask_padding).item()-1)\n",
    "                    \n",
    "                    batch_loss_eval = batch_loss_eval + torch.sum(dec_mask_padding * criterion(predicted, target)) / target_len\n",
    "                    batch_acc_eval += (target == predicted.argmax(dim=1)).sum().item() / target.size(0)\n",
    "                if config.is_coverage:\n",
    "                    batch_loss_eval = batch_loss_eval + cov_loss_wt * torch.sum(batch_coverage_loss)\n",
    "                \n",
    "                epoch_loss_eval += batch_loss_eval.item() / Hyparameters_config['batch_size']\n",
    "                epoch_acc_eval += batch_acc_eval.item() / Hyparameters_config['batch_size']\n",
    "        \n",
    "        del text, news, extend_token_id, output, batch_coverage_loss, batch_loss_eval, batch_acc_eval\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # 参数打印\n",
    "        duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "        print(\"Time: {} | Epoch: {}/{} | train_loss: {:.3} | train_acc: {:.3} | eval_loss: {:.3} | eval_acc: {:.3}\".format(\n",
    "            duration, epoch, num_epochs, epoch_loss_train/len(train_iter), epoch_acc_train/len(train_iter),\n",
    "            epoch_loss_eval/len(valid_iter), epoch_acc_eval/len(valid_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 num_cuda:  1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from config import config\n",
    "from utils.data_preprocess import preprocess_text\n",
    "import pickle\n",
    "config = config()\n",
    "\n",
    "# 清洗文本\n",
    "train_text, train_news = preprocess_text(config.valid_path, config.stopwords_path)\n",
    "valid_text, valid_news = preprocess_text(config.test_path, config.stopwords_path)\n",
    "\n",
    "# 建立词典\n",
    "vocab, extend_vocab = build_vocab(train_text+valid_text, train_news+valid_news, min_freq=3)\n",
    "vocab_size,extend_vocab_size = len(vocab), len(extend_vocab)\n",
    "with open(config.vocab_path, 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "with open(config.extend_vocab_path, 'wb') as f:\n",
    "    pickle.dump(extend_vocab, f)\n",
    "\n",
    "# 构建dataset，tensor格式\n",
    "train_text_dataset,train_extend_dataset = build_dataset(vocab, extend_vocab, train_text, config.max_len_text, is_extend_vocab=True)\n",
    "train_news_dataset,_ = build_dataset(vocab, extend_vocab, train_news, config.max_len_news, sentence_type=\"summary\")\n",
    "train_dataset = TensorDataset(train_text_dataset, train_news_dataset, train_extend_dataset)\n",
    "\n",
    "valid_text_dataset,valid_extend_dataset = build_dataset(vocab, extend_vocab, valid_text, config.max_len_text, is_extend_vocab=True)\n",
    "valid_news_dataset,_ = build_dataset(vocab, extend_vocab, valid_news, config.max_len_news, sentence_type=\"summary\")\n",
    "valid_dataset = TensorDataset(valid_text_dataset, valid_news_dataset, valid_extend_dataset)\n",
    "\n",
    "# 加载预训练的word2vec模型（使用搜狗新闻训练得到的word2vec），维度是300\n",
    "vocab.update(extend_vocab)\n",
    "pre_embeddings = get_pretrained_embedding(vocab, config.pretrained_vector_path, vector_dim=300)\n",
    "\n",
    "num_epochs = 5\n",
    "Hyparameters_config = {\n",
    "    'lr': 5e-3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 4,\n",
    "    'lr_gamma': 0.1,\n",
    "    'patience': 2,\n",
    "    'save_state_epoch': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([30.9879], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   1%|          | 1/125 [00:07<15:07,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-5.1714, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "8.746971130371094 0.10891088843345642\n",
      "tensor([32.9647], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   2%|▏         | 2/125 [00:14<14:52,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-3.3966, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "17.988140106201172 0.2599009871482849\n",
      "tensor([31.9084], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   2%|▏         | 3/125 [00:21<14:37,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-2.9929, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "26.965240478515625 0.38861386477947235\n",
      "tensor([33.2419], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   3%|▎         | 4/125 [00:28<14:25,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-2.9362, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "36.275726318359375 0.5222772359848022\n",
      "tensor([32.7924], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   4%|▍         | 5/125 [00:35<14:13,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-2.6300, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "45.47383213043213 0.6485148668289185\n",
      "tensor([30.9194], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   5%|▍         | 6/125 [00:42<14:11,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-1.8939, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "54.203675270080566 0.769801989197731\n",
      "tensor([30.2970], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   6%|▌         | 7/125 [00:49<14:04,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-1.1493, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "62.777931213378906 0.8910891190171242\n",
      "tensor([31.9416], device='cuda:0', grad_fn=<AddBackward0>) tensor(4., device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   6%|▋         | 8/125 [00:57<13:56,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder的第0层更新幅度： tensor(-0.5823, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "71.76332950592041 0.9975247606635094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training for epoch 0:   6%|▋         | 8/125 [01:00<14:38,  7.51s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-79a41f586615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointerGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHyparameters_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fa6afb002ead>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(model, train_dataset, valid_dataset, num_epochs, Hyparameters_config, cov_loss_wt)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_coverage_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_extend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, seq_len, vocab_size + extend_vocab_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mbatch_loss_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_acc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/accelerate/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/cuda/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f8517971b9c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, target, text_extend)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0menc_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0为pad id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0menc_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f8517971b9c0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0menc_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0为pad id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0menc_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# encoder 使用的是单层双向GRU\n",
    "encoder = Encoder(vocab_size, 300, 300, n_layers=1, use_pretrained_embeddings=True, pre_embeddings=pre_embeddings)\n",
    "# decoder 使用的是双向单层GRU\n",
    "decoder = Decoder(vocab_size, 300, 300, n_layers=1, use_pretrained_embeddings=True, pre_embeddings=pre_embeddings)\n",
    "\n",
    "model = PointerGenerator(encoder, decoder, extend_vocab_size, 300)\n",
    "trainer(model, train_dataset, valid_dataset, num_epochs, Hyparameters_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
